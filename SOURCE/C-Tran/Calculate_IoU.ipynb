{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from unet import UNet\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathTrain = 'data/food/train/'\n",
    "pathVal = 'data/food/val/'\n",
    "annotation_dir_train = pathTrain + \"annotations.json\"\n",
    "objData_train = json.load(open(annotation_dir_train))\n",
    "\n",
    "annotation_dir_val = pathVal + \"annotations.json\"\n",
    "objData_val = json.load(open(annotation_dir_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def crop_seg(coordinate_matrix, width, height):\n",
    "def crop_seg(coordinate_matrix):\n",
    "    new_list = []\n",
    "    for i in range(0, len(coordinate_matrix)):\n",
    "        for j in coordinate_matrix[i]:\n",
    "            new_list.append(j)\n",
    "\n",
    "    coordinate_matrix = np.array(new_list)\n",
    "    x_coordinate = coordinate_matrix[::2]\n",
    "    y_coordinate = coordinate_matrix[1::2]\n",
    "    top_left = np.array([x_coordinate.min(), y_coordinate.min()])\n",
    "    bottom_right = np.array([x_coordinate.max(), y_coordinate.max()])\n",
    "    # temp = bottom_right*1.1\n",
    "    # bottom_right[0] = min(temp[0], width)\n",
    "    # bottom_right[1] = min(temp[1], height)\n",
    "\n",
    "    return top_left, bottom_right\n",
    "\n",
    "def crop_image_by_mask(mask, width, height):\n",
    "    array_2d = mask.transpose(1,2,0).reshape(-1, mask.shape[0])\n",
    "    # sau khi transpose x -> y, y -> x. Do ฤรณ Row = x, y = col\n",
    "\n",
    "    row_array, col_array = np.where(array_2d == 1)\n",
    "    x_array = row_array\n",
    "    y_array = col_array\n",
    "    if x_array.size == 0 or y_array.size == 0:\n",
    "        return (0, 0, width, height)\n",
    "    min_x, min_y = x_array.min(), y_array.min()\n",
    "    max_x, max_y = x_array.max(), y_array.max()\n",
    "\n",
    "    width_scale = width/512\n",
    "    height_scale = height/512\n",
    "\n",
    "    min_x = float(min_x*width_scale)\n",
    "    min_y = float(min_y*height_scale)\n",
    "    max_x = float(max_x*width_scale)\n",
    "    max_y = float(max_y*height_scale)\n",
    "\n",
    "    return (min_x, min_y, max_x, max_y)\n",
    "\n",
    "\n",
    "def calculate_IOU(seg_box_1, seg_box_2):\n",
    "    coor_x = np.sort(np.array([seg_box_1[0], seg_box_1[2], seg_box_2[0], seg_box_2[2]]))[1:3]\n",
    "    coor_y = np.sort(np.array([seg_box_1[1], seg_box_1[3], seg_box_2[1], seg_box_2[3]]))[1:3]\n",
    "    s_inter = (coor_x[0]-coor_x[1])*(coor_y[0]-coor_y[1])\n",
    "    s_union = (seg_box_1[0]-seg_box_1[2])*(seg_box_1[1]-seg_box_1[3]) + \\\n",
    "        (seg_box_2[0]-seg_box_2[2])*(seg_box_2[1]-seg_box_2[3]) - s_inter\n",
    "    iou = s_inter/s_union\n",
    "\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_save_path = 'data/food_new_vrs/val/images/'\n",
    "original_val_path = 'data/food/val/images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_pth = \"./Segmentation_model/Unet/UNet-PyTorch/models/unet.pth\"\n",
    "\n",
    "model = UNet(in_channels=3, num_classes=1).to(device)\n",
    "model.load_state_dict(torch.load(model_pth, map_location=torch.device(device)))\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate IoU for valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_image_val = 0\n",
    "sum_iou_val = 0\n",
    "for element in objData_val['images']:\n",
    "    key = element['id']\n",
    "    image_name = element['file_name']\n",
    "    open_path = original_val_path + image_name\n",
    "    get_image = Image.open(open_path)\n",
    "    width, height = get_image.size\n",
    "    coordinate_matrix = []\n",
    "    for i in objData_val['annotations']:\n",
    "        if i['image_id'] == key:\n",
    "            coordinate_matrix.append(i['segmentation'][0])\n",
    "    top_left, bottom_right = crop_seg(coordinate_matrix)\n",
    "    crop_box_1 = (top_left[0], top_left[1], bottom_right[0], bottom_right[1])\n",
    "\n",
    "    img = transform(get_image).float().to(device)\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    pred_mask = model(img)\n",
    "\n",
    "    pred_mask = pred_mask.squeeze(0).cpu().detach()\n",
    "    pred_mask = pred_mask.permute(1, 2, 0)\n",
    "    pred_mask[pred_mask < 0] = 0\n",
    "    pred_mask[pred_mask > 0] = 1\n",
    "\n",
    "    mask = pred_mask.numpy()\n",
    "    crop_box_2 = crop_image_by_mask(mask, width, height)\n",
    "    iou = calculate_IOU(crop_box_1, crop_box_2)\n",
    "    sum_iou_val += iou\n",
    "    num_image_val +=1\n",
    "\n",
    "avg_iou_val = sum_iou_val/num_image_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5057986669849921\n"
     ]
    }
   ],
   "source": [
    "print(avg_iou_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate IoU for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_save_path = 'data/food_new_vrs/train/images/'\n",
    "original_train_path = 'data/food/train/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_image_train = 0\n",
    "sum_iou_train = 0\n",
    "for element in objData_train['images']:\n",
    "    key = element['id']\n",
    "    image_name = element['file_name']\n",
    "    open_path = train_save_path + image_name\n",
    "    get_image = Image.open(open_path)\n",
    "    width, height = get_image.size\n",
    "    coordinate_matrix = []\n",
    "    for i in objData_train['annotations']:\n",
    "        if i['image_id'] == key:\n",
    "            coordinate_matrix.append(i['segmentation'][0])\n",
    "    top_left, bottom_right = crop_seg(coordinate_matrix)\n",
    "    crop_box_1 = (top_left[0], top_left[1], bottom_right[0], bottom_right[1])\n",
    "\n",
    "    img = transform(get_image).float().to(device)\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    pred_mask = model(img)\n",
    "\n",
    "    pred_mask = pred_mask.squeeze(0).cpu().detach()\n",
    "    pred_mask = pred_mask.permute(1, 2, 0)\n",
    "    pred_mask[pred_mask < 0] = 0\n",
    "    pred_mask[pred_mask > 0] = 1\n",
    "\n",
    "    mask = pred_mask.numpy()\n",
    "    crop_box_2 = crop_image_by_mask(mask, width, height)\n",
    "    iou = calculate_IOU(crop_box_1, crop_box_2)\n",
    "    sum_iou_train += iou\n",
    "    num_image_train += 1\n",
    "\n",
    "avg_iou = sum_iou_train/num_image_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.419224194536759\n"
     ]
    }
   ],
   "source": [
    "print(avg_iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data/food_new_vrs/train/images/135204.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = transform(get_image).float().to(device)\n",
    "# img = img.unsqueeze(0)\n",
    "# pred_mask = model(img)\n",
    "# pred_mask = pred_mask.squeeze(0).cpu().detach()\n",
    "# pred_mask = pred_mask.permute(1, 2, 0)\n",
    "# pred_mask[pred_mask < 0] = 0\n",
    "# pred_mask[pred_mask > 0] = 1\n",
    "# mask = pred_mask.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(mask)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
